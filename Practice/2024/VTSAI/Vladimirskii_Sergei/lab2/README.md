# Задание #

1) Изучите ноутбук для данной работы
2) Выберите две стратегии для своей среды
3) Провести эксперименты, изменяя параметры стратегий, чтобы более глубоко понять их влияние на обучение модели.
4) Опишите выводы в readme и загрузите свои файлы на github.

# Среда Car Racing #

## Вывод ##

В ходе выполнения данной лабораторной работы был проведен сравнительный анализ двух алгоритмов 
обучения с подкреплением: DDPG и SAC.

DDPG - алгоритм глубоких детерминированных градиентов политики, использует epsilon-greedy стратегию, добавляя шум к выбранному действию во время исследования

SAC - алгоритм мягких критических факторов, использует стратегию исследования softmax через термин энтропии в SAC. Термин энтропия поощряет мягкое, вероятностное распределение действий, способствуя исследованию.

Наиболее успешным для решения данной задачи (Car racing) является алгоритм SAC со значением learning rate 0.001.